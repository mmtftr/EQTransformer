{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvQXTBlRCTah"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDgnxZaG_9LV"
      },
      "outputs": [],
      "source": [
        "#@title Dependencies and Imports\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%pip install -q lightning click transformers goatools toml wget fastobo torch_xla\n",
        "\n",
        "from google.colab import userdata, drive\n",
        "import os\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6ic7ZNNBICT",
        "outputId": "29ba5ede-70ad-4694-ed16-95c7603b2d34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#@title Environment Variables\n",
        "github_pat = userdata.get(\"GITHUB_PAT\")\n",
        "wandb_key = userdata.get(\"WANDB_API_KEY\")\n",
        "os.environ[\"WANDB_API_KEY\"] = wandb_key\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilPwF43_ANfK",
        "outputId": "eabcf978-1f95-4d81-ff34-e9b319bcf247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/contempro/work\n"
          ]
        }
      ],
      "source": [
        "#@title Clone and cd\n",
        "if os.getcwd() != \"/content/contempro/work\":\n",
        "  if not Path(\"/content/contempro\").exists():\n",
        "    !git clone https://{github_pat}@github.com/boun-tabi-lifelu/contempro.git\n",
        "  %cd /content/contempro/work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2m4uRJ5GqCk"
      },
      "source": [
        "# Data Fetching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAm4NYs5_-tj",
        "outputId": "ab08bf83-2028-42e4-fff6-18d696422a7f",
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  work-pfresgo-data.zip\n",
            "  inflating: __MACOSX/._pfresgo      \n",
            "  inflating: pfresgo/.DS_Store       \n",
            "  inflating: __MACOSX/pfresgo/._.DS_Store  \n",
            "  inflating: pfresgo/annot.tsv       \n",
            "  inflating: __MACOSX/pfresgo/._annot.tsv  \n",
            "  inflating: pfresgo/nrPDB-GO_2019.06.18_test.csv  \n",
            "  inflating: __MACOSX/pfresgo/._nrPDB-GO_2019.06.18_test.csv  \n",
            "  inflating: pfresgo/train.txt       \n",
            "  inflating: __MACOSX/pfresgo/._train.txt  \n",
            "  inflating: pfresgo/go.obo          \n",
            "  inflating: __MACOSX/pfresgo/._go.obo  \n",
            "  inflating: pfresgo/ontology.embeddings.npy  \n",
            "  inflating: __MACOSX/pfresgo/._ontology.embeddings.npy  \n",
            "  inflating: pfresgo/valid.txt       \n",
            "  inflating: __MACOSX/pfresgo/._valid.txt  \n",
            "  inflating: pfresgo/nrPDB-GO_2019.06.18_sequences.fasta  \n",
            "  inflating: __MACOSX/pfresgo/._nrPDB-GO_2019.06.18_sequences.fasta  \n",
            "  inflating: pfresgo/test.txt        \n",
            "  inflating: __MACOSX/pfresgo/._test.txt  \n"
          ]
        }
      ],
      "source": [
        "#@title Setup data\n",
        "!mkdir -p datasets\n",
        "!cp /content/drive/MyDrive/research/contempro/work-pfresgo-data.zip ./datasets\n",
        "!cd datasets && unzip -o work-pfresgo-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2YsjSuSEfxB"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/research/per_residue_embeddings.h5 ./datasets/pfresgo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP_aCDP3CbOg"
      },
      "source": [
        "# Test DataModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "KJ4uH1T0_9LV",
        "outputId": "061bc8b8-171a-4044-8127-9afa5f3541cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/mmtf/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/Users/mmtf/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ~~~~~~~~~~~~~~~^^^^^^\n  File \"/Users/mmtf/p/research/contempro/work/data/datamodule.py\", line 236, in collate_fn\n    seq_emb_dim = batch[0].residue_embeddings.shape[1]\n                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\nIndexError: tuple index out of range\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[55], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m dm\u001b[38;5;241m.\u001b[39msetup()\n\u001b[1;32m     11\u001b[0m dl \u001b[38;5;241m=\u001b[39m dm\u001b[38;5;241m.\u001b[39mtrain_dataloader()\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
            "File \u001b[0;32m~/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1465\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1491\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/_utils.py:715\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
            "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/mmtf/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/Users/mmtf/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ~~~~~~~~~~~~~~~^^^^^^\n  File \"/Users/mmtf/p/research/contempro/work/data/datamodule.py\", line 236, in collate_fn\n    seq_emb_dim = batch[0].residue_embeddings.shape[1]\n                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\nIndexError: tuple index out of range\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from data.datamodule import PFresGODataModule\n",
        "\n",
        "dm = PFresGODataModule(\n",
        "    data_dir=\"./datasets/pfresgo\",\n",
        "    ontology=\"molecular_function\",\n",
        "    num_workers=10\n",
        ")\n",
        "dm.setup()\n",
        "dl = dm.train_dataloader()\n",
        "next(iter(dl))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucaOJu-CCeBJ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN5bPsH5847C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "ZoVyhFfj_9LV",
        "outputId": "7308291b-fe19-4f8c-a35d-82111b7c3c4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmmtftr\u001b[0m (\u001b[33mmmtf\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/contempro/work/wandb/run-20241211_142407-fps8e4fo</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mmtf/contempro/runs/fps8e4fo' target=\"_blank\">treasured-flower-14</a></strong> to <a href='https://wandb.ai/mmtf/contempro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mmtf/contempro' target=\"_blank\">https://wandb.ai/mmtf/contempro</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mmtf/contempro/runs/fps8e4fo' target=\"_blank\">https://wandb.ai/mmtf/contempro/runs/fps8e4fo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "INFO:lightning.pytorch.utilities.rank_zero:You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "%run -i train.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}