{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvQXTBlRCTah"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SDgnxZaG_9LV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "463ec47d-60c5-4c18-d06a-34c8ee6cc58a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#@title Dependencies and Imports\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%pip install -q lightning click transformers goatools toml wget fastobo torch_xla wandb\n",
        "\n",
        "from google.colab import userdata, drive\n",
        "import os\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6ic7ZNNBICT",
        "outputId": "e4a0ef30-2f68-424c-c30d-f809ab610764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Environment Variables\n",
        "github_pat = userdata.get(\"GITHUB_PAT\")\n",
        "wandb_key = userdata.get(\"WANDB_API_KEY\")\n",
        "os.environ[\"WANDB_API_KEY\"] = wandb_key\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilPwF43_ANfK",
        "outputId": "91d9816d-915a-4c6f-aa57-5faaf2c45382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'contempro'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "remote: Counting objects: 100% (269/269), done.\u001b[K\n",
            "remote: Compressing objects: 100% (171/171), done.\u001b[K\n",
            "remote: Total 269 (delta 128), reused 220 (delta 81), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (269/269), 6.37 MiB | 46.60 MiB/s, done.\n",
            "Resolving deltas: 100% (128/128), done.\n",
            "/content/contempro/work\n"
          ]
        }
      ],
      "source": [
        "#@title Clone and cd\n",
        "if os.getcwd() != \"/content/contempro/work\":\n",
        "  if not Path(\"/content/contempro\").exists():\n",
        "    !git clone https://{github_pat}@github.com/boun-tabi-lifelu/contempro.git\n",
        "  %cd /content/contempro/work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2m4uRJ5GqCk"
      },
      "source": [
        "# Data Fetching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAm4NYs5_-tj",
        "outputId": "a4c9225a-fe2b-4842-c644-ca136be4521a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  work-pfresgo-data.zip\n",
            "   creating: pfresgo/\n",
            "  inflating: __MACOSX/._pfresgo      \n",
            "  inflating: pfresgo/.DS_Store       \n",
            "  inflating: __MACOSX/pfresgo/._.DS_Store  \n",
            "  inflating: pfresgo/annot.tsv       \n",
            "  inflating: __MACOSX/pfresgo/._annot.tsv  \n",
            "  inflating: pfresgo/nrPDB-GO_2019.06.18_test.csv  \n",
            "  inflating: __MACOSX/pfresgo/._nrPDB-GO_2019.06.18_test.csv  \n",
            "  inflating: pfresgo/train.txt       \n",
            "  inflating: __MACOSX/pfresgo/._train.txt  \n",
            "  inflating: pfresgo/go.obo          \n",
            "  inflating: __MACOSX/pfresgo/._go.obo  \n",
            "  inflating: pfresgo/ontology.embeddings.npy  \n",
            "  inflating: __MACOSX/pfresgo/._ontology.embeddings.npy  \n",
            "  inflating: pfresgo/valid.txt       \n",
            "  inflating: __MACOSX/pfresgo/._valid.txt  \n",
            "  inflating: pfresgo/nrPDB-GO_2019.06.18_sequences.fasta  \n",
            "  inflating: __MACOSX/pfresgo/._nrPDB-GO_2019.06.18_sequences.fasta  \n",
            "  inflating: pfresgo/test.txt        \n",
            "  inflating: __MACOSX/pfresgo/._test.txt  \n"
          ]
        }
      ],
      "source": [
        "#@title Setup data\n",
        "!mkdir -p datasets\n",
        "!cp /content/drive/MyDrive/research/contempro/work-pfresgo-data.zip ./datasets\n",
        "!cd datasets && unzip -o work-pfresgo-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R2YsjSuSEfxB"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/research/per_residue_embeddings.h5 ./datasets/pfresgo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP_aCDP3CbOg"
      },
      "source": [
        "# Test DataModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "KJ4uH1T0_9LV",
        "outputId": "061bc8b8-171a-4044-8127-9afa5f3541cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/mmtf/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/Users/mmtf/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ~~~~~~~~~~~~~~~^^^^^^\n  File \"/Users/mmtf/p/research/contempro/work/data/datamodule.py\", line 236, in collate_fn\n    seq_emb_dim = batch[0].residue_embeddings.shape[1]\n                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\nIndexError: tuple index out of range\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[55], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m dm\u001b[38;5;241m.\u001b[39msetup()\n\u001b[1;32m     11\u001b[0m dl \u001b[38;5;241m=\u001b[39m dm\u001b[38;5;241m.\u001b[39mtrain_dataloader()\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
            "File \u001b[0;32m~/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1465\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1491\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/_utils.py:715\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
            "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/mmtf/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/Users/mmtf/p/research/contempro/work/.pixi/envs/default/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ~~~~~~~~~~~~~~~^^^^^^\n  File \"/Users/mmtf/p/research/contempro/work/data/datamodule.py\", line 236, in collate_fn\n    seq_emb_dim = batch[0].residue_embeddings.shape[1]\n                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\nIndexError: tuple index out of range\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from data.datamodule import PFresGODataModule\n",
        "\n",
        "dm = PFresGODataModule(\n",
        "    data_dir=\"./datasets/pfresgo\",\n",
        "    ontology=\"molecular_function\",\n",
        "    num_workers=10\n",
        ")\n",
        "dm.setup()\n",
        "dl = dm.train_dataloader()\n",
        "next(iter(dl))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucaOJu-CCeBJ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ZoVyhFfj_9LV",
        "outputId": "2ababf7c-be91-4cf5-e3f2-d569033fe998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'wandb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/content/contempro/work/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_toml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wandb'"
          ]
        }
      ],
      "source": [
        "%run -i train.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data.datamodule import PFresGODataset\n",
        "import h5py\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from pathlib import Path\n",
        "def _load_protein_ids(filename: Path) -> List[str]:\n",
        "  \"\"\"Load protein IDs from a text file\"\"\"\n",
        "  with open(filename) as f:\n",
        "    return [line.strip() for line in f]\n",
        "\n",
        "\n",
        "def _load_residue_embeddings(prot_ids, residue_emb_file: Path) -> dict[str, np.ndarray]:\n",
        "  with h5py.File(residue_emb_file, 'r') as f:\n",
        "    return {\n",
        "        # TODO: remove the last dimension\n",
        "        protein: f[f\"{protein} nrPDB\"][:]\n",
        "        for protein in prot_ids\n",
        "    }\n",
        "\n",
        "ids = []\n",
        "for slic in [\"train\", \"valid\", \"test\"]:\n",
        "  ids += _load_protein_ids(f\"datasets/pfresgo/{slic}.txt\")"
      ],
      "metadata": {
        "id": "b2EFOwycJWYS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embs = _load_residue_embeddings(ids, \"datasets/pfresgo/per_residue_embeddings.h5\")"
      ],
      "metadata": {
        "id": "FdMg934oKKRF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ivCMAA-hbzDZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/contempro/work"
      ],
      "metadata": {
        "id": "So8Dy8B9o3WD",
        "outputId": "cffcb0bb-7d66-48ab-8f47-bab7ca398a6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/contempro/work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez_compressed(\"embs_2.npz\", **embs)"
      ],
      "metadata": {
        "id": "RRelqKH9b02j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}